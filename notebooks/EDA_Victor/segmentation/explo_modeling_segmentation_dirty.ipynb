{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd5db8be",
      "metadata": {
        "id": "cd5db8be"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f7b10be",
      "metadata": {
        "id": "4f7b10be"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906cb6d5",
      "metadata": {
        "id": "906cb6d5"
      },
      "source": [
        "# Download Kaggle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9447c55a",
      "metadata": {
        "id": "9447c55a"
      },
      "outputs": [],
      "source": [
        "# import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "# path = kagglehub.dataset_download(\"mateuszbuda/lgg-mri-segmentation\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmRfHkHlxAWq",
      "metadata": {
        "id": "fmRfHkHlxAWq"
      },
      "source": [
        "# Setup with Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DfkdbyqUxGw0",
      "metadata": {
        "id": "DfkdbyqUxGw0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GI2s0PfrxVt1",
      "metadata": {
        "id": "GI2s0PfrxVt1"
      },
      "outputs": [],
      "source": [
        "# D√©finir le chemin o√π se trouve ton fichier ZIP\n",
        "# Remplace 'brain_tumor_project' par le nom du dossier que tu as cr√©√©\n",
        "ZIP_PATH = '/content/drive/MyDrive/brain-tumor-detection-project/kaggle_3m.zip'\n",
        "\n",
        "# D√©finir le r√©pertoire de destination (le dossier temporaire de Colab)\n",
        "DEST_PATH = '/content/data/'\n",
        "os.makedirs(DEST_PATH, exist_ok=True)\n",
        "\n",
        "# D√©zipper le fichier (commande Linux ex√©cut√©e dans Colab)\n",
        "!unzip -q \"{ZIP_PATH}\" -d \"{DEST_PATH}\"\n",
        "print(\"‚úÖ D√©compression termin√©e.\")\n",
        "\n",
        "# D√©finir le nouveau chemin racine des donn√©es\n",
        "DATA_DIR = os.path.join(DEST_PATH, 'kaggle_3m')\n",
        "\n",
        "# V√©rification : Doit imprimer le chemin vers un patient\n",
        "print(f\"Nouveau chemin racine des donn√©es : {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qj3-Oo5wzCLa",
      "metadata": {
        "id": "qj3-Oo5wzCLa"
      },
      "outputs": [],
      "source": [
        "# 1. Rappel du chemin que tu utilises actuellement\n",
        "print(f\"üëâ Ton chemin DATA_DIR actuel est : {DATA_DIR}\")\n",
        "\n",
        "# 2. V√©rification d'existence\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(\"‚ùå ERREUR FATALE : Ce dossier n'existe pas ! Le chemin est faux.\")\n",
        "else:\n",
        "    print(\"‚úÖ Le dossier racine existe. Regardons ce qu'il y a dedans...\")\n",
        "\n",
        "    # 3. Lister le contenu direct\n",
        "    contenu = os.listdir(DATA_DIR)\n",
        "    print(f\"üìÇ Contenu trouv√© ({len(contenu)} √©l√©ments) :\")\n",
        "    print(contenu[:10]) # On affiche les 10 premiers\n",
        "\n",
        "    # 4. V√©rification du pi√®ge classique (\"Dossier dans un dossier\")\n",
        "    # Souvent, le d√©zippage cr√©e un sous-dossier suppl√©mentaire\n",
        "    if 'kaggle_3m' in contenu:\n",
        "        print(\"\\n‚ö†Ô∏è ALERTE : Je vois un dossier 'kaggle_3m' √Ä L'INT√âRIEUR de ton dossier.\")\n",
        "        print(\"üí° SOLUTION : Ton chemin s'arr√™te trop t√¥t.\")\n",
        "        print(f\"Essaie de changer DATA_DIR en : {os.path.join(DATA_DIR, 'kaggle_3m')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758b2dbc",
      "metadata": {
        "id": "758b2dbc"
      },
      "source": [
        "# Setup in local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17934f6",
      "metadata": {
        "id": "f17934f6"
      },
      "outputs": [],
      "source": [
        "# Bien penser √† remplacer le chmin vers la source de donn√©es\n",
        "DATA_DIR = '/Users/victor/code/afallo/brain_tumor_detection_project/raw_data/segmentation/kaggle_3m'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5b1348",
      "metadata": {
        "id": "3c5b1348"
      },
      "source": [
        "# Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5798db",
      "metadata": {
        "id": "ec5798db"
      },
      "source": [
        "## To DF + Balancing des classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f363ba7f",
      "metadata": {
        "id": "f363ba7f"
      },
      "outputs": [],
      "source": [
        "def create_diagnosed_dataframe(data_dir):\n",
        "    data = []\n",
        "\n",
        "    print(\"üïµÔ∏è‚Äç‚ôÇÔ∏è Analyse et v√©rification des fichiers en cours...\")\n",
        "\n",
        "    for dirname, _, filenames in os.walk(data_dir):\n",
        "        for filename in filenames:\n",
        "            if 'mask' in filename and filename.endswith('.tif'):\n",
        "\n",
        "                mask_path = os.path.join(dirname, filename)\n",
        "                image_filename = filename.replace('_mask', '')\n",
        "                image_path = os.path.join(dirname, image_filename)\n",
        "\n",
        "                # 1. V√©rification d'int√©grit√© : L'image source existe-t-elle ?\n",
        "                if os.path.exists(image_path):\n",
        "\n",
        "                    # 2. V√©rification de contenu : Le masque est-il vide ?\n",
        "                    # On lit le masque en niveau de gris (0 = noir, 255 = blanc)\n",
        "                    try:\n",
        "                        mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                        # Si la valeur max est > 0, c'est qu'il y a une tumeur (du blanc)\n",
        "                        has_tumor = 1 if np.max(mask_img) > 0 else 0\n",
        "\n",
        "                        data.append({\n",
        "                            'image_path': image_path,\n",
        "                            'mask_path': mask_path,\n",
        "                            'has_tumor': has_tumor\n",
        "                        })\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Fichier corrompu ignor√© : {filename} ({e})\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Ex√©cution\n",
        "df = create_diagnosed_dataframe(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9799e6e8",
      "metadata": {
        "id": "9799e6e8"
      },
      "outputs": [],
      "source": [
        "def balance_dataset(df):\n",
        "    # 1. On s√©pare les deux groupes\n",
        "    df_tumor = df[df['has_tumor'] == 1]\n",
        "    df_healthy = df[df['has_tumor'] == 0]\n",
        "\n",
        "    print(f\"Original -> Tumeurs: {len(df_tumor)} | Sains: {len(df_healthy)}\")\n",
        "\n",
        "    # 2. On d√©cide combien de sains on garde\n",
        "    # Pour un U-Net, un ratio 50/50 ou 60/40 est souvent id√©al.\n",
        "    # Ici, on garde autant de sains que de tumeurs (ratio 1:1)\n",
        "    n_samples = len(df_tumor)\n",
        "\n",
        "    # Si on a moins de sains que de tumeurs (rare), on prend tout\n",
        "    if len(df_healthy) > n_samples:\n",
        "        df_healthy_sampled = df_healthy.sample(n=n_samples, random_state=42)\n",
        "    else:\n",
        "        df_healthy_sampled = df_healthy\n",
        "\n",
        "    # 3. On recombine et on m√©lange\n",
        "    df_balanced = pd.concat([df_tumor, df_healthy_sampled])\n",
        "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return df_balanced\n",
        "\n",
        "# --- EX√âCUTION ---\n",
        "df_final = balance_dataset(df)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset √âquilibr√© Pr√™t !\")\n",
        "print(f\"Taille finale : {len(df_final)} images\")\n",
        "print(f\"R√©partition : 50% Tumeurs / 50% Sains (environ)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd47881d",
      "metadata": {
        "id": "fd47881d"
      },
      "outputs": [],
      "source": [
        "df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79cebc1e",
      "metadata": {
        "id": "79cebc1e"
      },
      "source": [
        "## Viz Mask tumeur & √©quilibre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd22c20",
      "metadata": {
        "id": "0bd22c20"
      },
      "outputs": [],
      "source": [
        "def visualize_data(df, n_samples=5):\n",
        "    plt.figure(figsize=(15, n_samples * 4))\n",
        "\n",
        "    # On prend n_samples indices au hasard dans le dataframe\n",
        "    indices = random.sample(range(len(df)), n_samples)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img_path = df.iloc[idx]['image_path']\n",
        "        mask_path = df.iloc[idx]['mask_path']\n",
        "\n",
        "        # Lecture des images\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Conversion BGR -> RGB pour l'affichage correct\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # --- Cr√©ation de la superposition (Overlay) ---\n",
        "        # On cr√©e une copie de l'image pour dessiner dessus\n",
        "        overlay = img.copy()\n",
        "\n",
        "        # On colorie en rouge l√† o√π le masque est blanc (tumeur)\n",
        "        # mask > 0 renvoie les pixels de la tumeur\n",
        "        overlay[mask > 0] = [255, 0, 0] # Rouge pur\n",
        "\n",
        "        # On applique la transparence (alpha blending)\n",
        "        # image_finale = alpha * overlay + (1-alpha) * image_originale\n",
        "        final_img = cv2.addWeighted(overlay, 0.4, img, 0.6, 0)\n",
        "\n",
        "        # --- Affichage ---\n",
        "        # 1. Image Originale\n",
        "        plt.subplot(n_samples, 3, i*3 + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image Originale (Patient {idx})\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # 2. Masque\n",
        "        plt.subplot(n_samples, 3, i*3 + 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(\"Masque (V√©rit√© Terrain)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # 3. Superposition\n",
        "        plt.subplot(n_samples, 3, i*3 + 3)\n",
        "        plt.imshow(final_img)\n",
        "        plt.title(\"Superposition\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Lancer la visualisation\n",
        "visualize_data(df_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef2912a",
      "metadata": {
        "id": "aef2912a"
      },
      "outputs": [],
      "source": [
        "# 1. Compter les valeurs exactes\n",
        "counts = df_final['has_tumor'].value_counts()\n",
        "\n",
        "print(\"--- R√©partition exacte ---\")\n",
        "print(counts)\n",
        "\n",
        "# 2. V√©rifier les pourcentages\n",
        "percentages = df_final['has_tumor'].value_counts(normalize=True) * 100\n",
        "print(\"\\n--- En pourcentage ---\")\n",
        "print(percentages)\n",
        "\n",
        "# 3. Visualisation graphique\n",
        "plt.figure(figsize=(6, 4))\n",
        "counts.plot(kind='bar', color=['#ff9999', '#66b3ff'])\n",
        "plt.title('√âquilibre des Classes (0 = Sain, 1 = Tumeur)')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Nombre d\\'images')\n",
        "plt.xticks(ticks=[0, 1], labels=['0 (Sain)', '1 (Tumeur)'], rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f844cadb",
      "metadata": {
        "id": "f844cadb"
      },
      "source": [
        "## Spliting des datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbaa5de4",
      "metadata": {
        "id": "bbaa5de4"
      },
      "outputs": [],
      "source": [
        "# --- 1. PARAM√àTRES GLOBAUX ---\n",
        "IMG_SIZE = 256      # On redimensionne tout en 256x256\n",
        "BATCH_SIZE = 32     # Le mod√®le verra 32 images √† la fois\n",
        "EPOCHS = 40         # On entra√Ænera potentiellement sur 40 tours\n",
        "\n",
        "# --- 2. S√âPARATION DES DONN√âES (TRAIN / VAL / TEST) ---\n",
        "# On divise d'abord en : 85% (Train+Val) et 15% (Test final)\n",
        "train_val_df, test_df = train_test_split(df_final, test_size=0.15, random_state=42)\n",
        "\n",
        "# On recoupe les 85% restants en : 85% Train et 15% Validation\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n",
        "\n",
        "print(f\"üìä Volume des donn√©es :\")\n",
        "print(f\"Train      : {len(train_df)} images (Pour apprendre)\")\n",
        "print(f\"Validation : {len(val_df)} images (Pour s'√©valuer en cours de route)\")\n",
        "print(f\"Test       : {len(test_df)} images (Pour l'examen final)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a381c040",
      "metadata": {
        "id": "a381c040"
      },
      "outputs": [],
      "source": [
        "# --- 3. CR√âATION DU G√âN√âRATEUR PERSONNALIS√â ---\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size=32, img_size=256, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end() # M√©lange au d√©marrage\n",
        "\n",
        "    def __len__(self):\n",
        "        # Nombre de \"paquets\" (batchs) par √©poque\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # S√©lectionne les indices pour ce batch\n",
        "        indexes = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Initialisation des tableaux vides\n",
        "        X = np.zeros((self.batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        y = np.zeros((self.batch_size, self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "\n",
        "        # Chargement des images et masques\n",
        "        for i, idx in enumerate(indexes):\n",
        "            # Chemins\n",
        "            img_path = self.df.iloc[idx]['image_path']\n",
        "            mask_path = self.df.iloc[idx]['mask_path']\n",
        "\n",
        "            # Traitement IMAGE\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (self.img_size, self.img_size)) # Redimensionner\n",
        "            img = img / 255.0  # Normalisation (0-1)\n",
        "            X[i] = img\n",
        "\n",
        "            # Traitement MASQUE\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
        "            # Le masque doit √™tre binaire (0 ou 1), pas (0 √† 255)\n",
        "            mask = mask / 255.0\n",
        "            mask = np.expand_dims(mask, axis=-1) # Ajouter la dimension de canal (256,256,1)\n",
        "            y[i] = mask\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # M√©lange les indices apr√®s chaque tour complet (√©poque)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# --- 4. INSTANCIATION DES G√âN√âRATEURS ---\n",
        "train_generator = DataGenerator(train_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
        "val_generator = DataGenerator(val_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
        "test_generator = DataGenerator(test_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE, shuffle=False)\n",
        "\n",
        "print(\"\\n‚úÖ G√©n√©rateurs pr√™ts ! Pr√™ts √† nourrir le mod√®le.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24aa1d54",
      "metadata": {
        "id": "24aa1d54"
      },
      "outputs": [],
      "source": [
        "# On tire un seul batch pour voir\n",
        "X_sample, y_sample = train_generator[0]\n",
        "print(f\"Format des Images (X) : {X_sample.shape}\") # Doit √™tre (32, 256, 256, 3)\n",
        "print(f\"Format des Masques (y): {y_sample.shape}\") # Doit √™tre (32, 256, 256, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y8Km3GacfHes",
      "metadata": {
        "id": "Y8Km3GacfHes"
      },
      "source": [
        "## Image Augmentation (Color Contrast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5GQaqtUvZGUU",
      "metadata": {
        "id": "5GQaqtUvZGUU"
      },
      "outputs": [],
      "source": [
        "def apply_clahe_color(img):\n",
        "    \"\"\"\n",
        "    Applique CLAHE en pr√©servant les couleurs via l'espace LAB.\n",
        "    \"\"\"\n",
        "    # 1. On convertit l'image BGR vers LAB\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # 2. On s√©pare les canaux (L = Luminosit√©, A et B = Couleurs)\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    # 3. On applique le CLAHE uniquement sur la Luminosit√© (L)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    l2 = clahe.apply(l)\n",
        "\n",
        "    # 4. On recolle les morceaux (Le L boost√© + les A et B d'origine)\n",
        "    lab_enhanced = cv2.merge((l2, a, b))\n",
        "\n",
        "    # 5. On reconvertit en BGR pour l'affichage/utilisation\n",
        "    enhanced_img = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return enhanced_img\n",
        "\n",
        "def visualize_contrast_enhancement(df, n_samples=3):\n",
        "    plt.figure(figsize=(15, n_samples * 4))\n",
        "\n",
        "    # Choix al√©atoire d'images AVEC tumeur\n",
        "    tumor_df = df[df['has_tumor'] == 1]\n",
        "    indices = random.sample(range(len(tumor_df)), n_samples)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img_path = tumor_df.iloc[idx]['image_path']\n",
        "        mask_path = tumor_df.iloc[idx]['mask_path']\n",
        "\n",
        "        # Lecture\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Application du CLAHE (Version couleur LAB)\n",
        "        enhanced = apply_clahe_color(img)\n",
        "\n",
        "        # --- AFFICHAGE ---\n",
        "\n",
        "        # 1. Image Originale (EN COULEUR)\n",
        "        plt.subplot(n_samples, 3, i*3 + 1)\n",
        "        # Conversion BGR -> RGB pour que Matplotlib affiche les bonnes couleurs\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(\"Originale (Couleur)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # 2. Image Am√©lior√©e (EN COULEUR)\n",
        "        plt.subplot(n_samples, 3, i*3 + 2)\n",
        "        # Conversion BGR -> RGB aussi pour l'image am√©lior√©e\n",
        "        enhanced_rgb = cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(enhanced_rgb)\n",
        "        plt.title(\"Apr√®s CLAHE (Contraste +)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # 3. Masque\n",
        "        plt.subplot(n_samples, 3, i*3 + 3)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(\"Localisation Tumeur\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# --- Lancement du test ---\n",
        "# On suppose que 'df_final' (ton dataframe √©quilibr√©) est toujours en m√©moire\n",
        "# Si tu l'as perdu, relance d'abord la cr√©ation du dataframe\n",
        "visualize_contrast_enhancement(df_final, n_samples=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RjISio-kfV6W",
      "metadata": {
        "id": "RjISio-kfV6W"
      },
      "outputs": [],
      "source": [
        "class ColorContrastDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size=32, img_size=256, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "\n",
        "        # Initialisation du CLAHE\n",
        "        # On l'appliquera uniquement sur la luminosit√© (L)\n",
        "        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # ATTENTION : Ici on remet 3 canaux pour la couleur\n",
        "        X = np.zeros((self.batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        y = np.zeros((self.batch_size, self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "\n",
        "        for i, idx in enumerate(indexes):\n",
        "            img_path = self.df.iloc[idx]['image_path']\n",
        "            mask_path = self.df.iloc[idx]['mask_path']\n",
        "\n",
        "            # --- 1. CHARGEMENT & TRAITEMENT COULEUR (LAB) ---\n",
        "            # Lecture standard en couleur (BGR par d√©faut dans OpenCV)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is not None:\n",
        "                # A. Conversion BGR -> LAB\n",
        "                lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "                # B. S√©paration des canaux\n",
        "                l, a, b = cv2.split(lab)\n",
        "\n",
        "                # C. Application du CLAHE sur la Luminosit√© (L)\n",
        "                l2 = self.clahe.apply(l)\n",
        "\n",
        "                # D. Fusion et retour en BGR\n",
        "                lab = cv2.merge((l2, a, b))\n",
        "                img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "                # E. Standardisation\n",
        "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "                img = img / 255.0  # Normalisation 0-1\n",
        "                # Pas besoin d'expand_dims ici car l'image a d√©j√† 3 canaux\n",
        "                X[i] = img\n",
        "\n",
        "            # --- 2. TRAITEMENT MASQUE ---\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if mask is not None:\n",
        "                mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
        "                mask = mask / 255.0\n",
        "                mask = (mask > 0.5).astype(np.float32) # Binarisation stricte\n",
        "                mask = np.expand_dims(mask, axis=-1)\n",
        "                y[i] = mask\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "print(\"‚úÖ Classe ColorContrastDataGenerator d√©finie !\")\n",
        "\n",
        "# Instanciation des 3 g√©n√©rateurs (Train, Val ET Test)\n",
        "train_gen_color = ColorContrastDataGenerator(train_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
        "val_gen_color = ColorContrastDataGenerator(val_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
        "test_gen_color = ColorContrastDataGenerator(test_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE, shuffle=False)\n",
        "\n",
        "print(\"‚úÖ Les 3 g√©n√©rateurs (y compris Test) sont pr√™ts en mode Couleur+CLAHE.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78f1503",
      "metadata": {
        "id": "a78f1503"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ocSW3ph369nF",
      "metadata": {
        "id": "ocSW3ph369nF"
      },
      "source": [
        "### Plot History Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-iiaM0mc3RSv",
      "metadata": {
        "id": "-iiaM0mc3RSv"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, title=\"Baseline Model Performance\"):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Graphique de la LOSS (Erreur)\n",
        "    ax1.plot(history.history['loss'], label='Train Loss')\n",
        "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax1.set_title(f'{title} - Loss (Plus bas est mieux)')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Dice Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Graphique du DICE SCORE (Pr√©cision)\n",
        "    ax2.plot(history.history['dice_coef'], label='Train Dice')\n",
        "    ax2.plot(history.history['val_dice_coef'], label='Validation Dice')\n",
        "    ax2.set_title(f'{title} - Dice Score (Plus haut est mieux)')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Dice Coefficient')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nUTBK6BZ63AX",
      "metadata": {
        "id": "nUTBK6BZ63AX"
      },
      "source": [
        "### Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e51f43e9",
      "metadata": {
        "id": "e51f43e9"
      },
      "outputs": [],
      "source": [
        "def predict_and_plot(model, df, n_samples=3):\n",
        "    \"\"\"\n",
        "    Prend le mod√®le, le dataframe de test, et affiche n pr√©dictions.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, n_samples * 4))\n",
        "\n",
        "    # On choisit des indices au hasard dans le dataset de TEST\n",
        "    # (Important : on ne teste pas sur ce qu'il a d√©j√† appris !)\n",
        "    indices = random.sample(range(len(df)), n_samples)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # 1. R√©cup√©ration des chemins\n",
        "        img_path = df.iloc[idx]['image_path']\n",
        "        mask_path = df.iloc[idx]['mask_path']\n",
        "\n",
        "        # 2. Pr√©paration de l'Image (Input)\n",
        "        # Lecture + Resize + Normalisation\n",
        "        img_raw = cv2.imread(img_path)\n",
        "        img_input = cv2.resize(img_raw, (256, 256))\n",
        "        img_input = img_input / 255.0 # Normalisation 0-1\n",
        "\n",
        "        # Le mod√®le attend un batch (1, 256, 256, 3), pas juste (256, 256, 3)\n",
        "        img_batch = np.expand_dims(img_input, axis=0)\n",
        "\n",
        "        # 3. PR√âDICTION (.predict se fait ici !)\n",
        "        pred_mask = model.predict(img_batch, verbose=0)\n",
        "\n",
        "        # 4. Post-traitement\n",
        "        # La sortie est une probabilit√© (ex: 0.8). On coupe √† 0.5 pour avoir 0 ou 1.\n",
        "        pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "        # On retire la dimension du batch pour l'affichage (256, 256)\n",
        "        pred_mask = np.squeeze(pred_mask)\n",
        "\n",
        "        # Lecture du Vrai Masque pour comparer\n",
        "        true_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        true_mask = cv2.resize(true_mask, (256, 256))\n",
        "\n",
        "        # --- AFFICHAGE ---\n",
        "        # Colonne 1 : Image Originale\n",
        "        plt.subplot(n_samples, 3, i*3 + 1)\n",
        "        plt.imshow(cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Radio Originale (Patient {idx})\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Colonne 2 : Vrai Masque (Ce qu'on attendait)\n",
        "        plt.subplot(n_samples, 3, i*3 + 2)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title(\"V√©rit√© Terrain (Cible)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Colonne 3 : Pr√©diction (Ce que l'IA a vu)\n",
        "        plt.subplot(n_samples, 3, i*3 + 3)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        plt.title(\"Pr√©diction IA\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb46424",
      "metadata": {
        "id": "deb46424"
      },
      "outputs": [],
      "source": [
        "# --- 1. D√âFINITION DES M√âTRIQUES (DICE) ---\n",
        "def dice_coef(y_true, y_pred):\n",
        "    # On aplatit les images pour comparer pixel par pixel\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    # Formule du Dice : (2 * Intersection) / (Total pixels pr√©dits + Total pixels r√©els)\n",
        "    # Le smooth=1 √©vite la division par z√©ro\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087ac8b4",
      "metadata": {
        "collapsed": true,
        "id": "087ac8b4"
      },
      "outputs": [],
      "source": [
        "def baseline_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Entr√©e\n",
        "    model.add(Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "\n",
        "    # --- ENCODEUR (Compression) ---\n",
        "    # On r√©duit simplement la taille pour capter le contexte\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2))) # -> 128x128\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2))) # -> 64x64\n",
        "\n",
        "    # --- BOTTLENECK ---\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # --- D√âCODEUR (Reconstruction) ---\n",
        "    # On regonfle sans aide (pas de skip connections)\n",
        "    model.add(UpSampling2D((2, 2))) # -> 128x128\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    model.add(UpSampling2D((2, 2))) # -> 256x256\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # --- SORTIE ---\n",
        "    model.add(Conv2D(1, (1, 1), activation='sigmoid')) # Probabilit√© 0-1\n",
        "\n",
        "    # Compilation (M√™mes m√©triques pour comparaison loyale)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=dice_coef_loss,  # On garde la m√™me loss custom\n",
        "                  metrics=['accuracy', dice_coef])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instanciation de la Baseline\n",
        "model_baseline = baseline_model(IMG_SIZE, IMG_SIZE, 3)\n",
        "model_baseline.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f92b2c9",
      "metadata": {
        "collapsed": true,
        "id": "5f92b2c9"
      },
      "outputs": [],
      "source": [
        "# --- 1. CONFIGURATION DES OUTILS DE CONTR√îLE ---\n",
        "callbacks = [\n",
        "    # Arr√™te l'entra√Ænement si la \"val_loss\" ne descend plus apr√®s 5 √©poques\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# --- 2. LANCEMENT DE L'ENTRA√éNEMENT ---\n",
        "print(\"üèÅ D√©but de l'entra√Ænement du Baseline Model...\")\n",
        "\n",
        "history_baseline = model_baseline.fit(\n",
        "    train_gen_color,\n",
        "    validation_data=val_gen_color,\n",
        "    epochs=30,  # On met 30, mais le EarlyStopping arr√™tera s√ªrement avant\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gk6c9sfl43Hx",
      "metadata": {
        "id": "Gk6c9sfl43Hx"
      },
      "outputs": [],
      "source": [
        "plot_history(history_baseline, title=\"Baseline Model Performance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb212aea",
      "metadata": {
        "id": "eb212aea"
      },
      "source": [
        "## Entra√Ænement Mini-Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ec5721",
      "metadata": {
        "id": "e8ec5721"
      },
      "outputs": [],
      "source": [
        "def mini_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = inputs\n",
        "\n",
        "    # --- NIVEAU 1 (Descente) ---\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    # --- NIVEAU 2 (Descente) ---\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # --- BOTTLENECK (Le fond) ---\n",
        "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    # --- REMONT√âE NIVEAU 2 (Avec Pont !) ---\n",
        "    u4 = UpSampling2D((2, 2))(c3)\n",
        "    # ICI C'EST LA CL√â : On recolle les infos de c2 (Niveau 2 original)\n",
        "    u4 = concatenate([u4, c2])\n",
        "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
        "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    # --- REMONT√âE NIVEAU 1 (Avec Pont !) ---\n",
        "    u5 = UpSampling2D((2, 2))(c4)\n",
        "    # ICI ON RECOLLE c1 (Niveau 1 original - Haute r√©solution)\n",
        "    u5 = concatenate([u5, c1])\n",
        "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # --- SORTIE ---\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    # On compile avec les m√™mes m√©triques pour comparer ce qui est comparable\n",
        "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy', dice_coef])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instanciation et R√©sum√©\n",
        "model_mini_unet = mini_unet_model(IMG_SIZE, IMG_SIZE, 3)\n",
        "model_mini_unet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1uLzsWpShhlZ",
      "metadata": {
        "id": "1uLzsWpShhlZ"
      },
      "source": [
        "### Si erreur dans les poids sur Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SLt1_pjc-wHw",
      "metadata": {
        "id": "SLt1_pjc-wHw"
      },
      "outputs": [],
      "source": [
        "model_mini_unet = mini_unet_model(IMG_SIZE, IMG_SIZE, 3)\n",
        "print(\"‚úÖ Mod√®le Mini U-Net reconstruit avec de nouveaux poids al√©atoires.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9lDSGABuiaoL",
      "metadata": {
        "id": "9lDSGABuiaoL"
      },
      "source": [
        "### Si pas d'erreur sur les poids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILM3fdLc-ycY",
      "metadata": {
        "id": "ILM3fdLc-ycY"
      },
      "outputs": [],
      "source": [
        "# --- 2. Lancement de l'Entra√Ænement ---\n",
        "print(\"üèÅ D√©but du nouvel entra√Ænement du MINI U-NET...\")\n",
        "print(f\"Objectif √† battre (Baseline) : Dice Score > 0.62\")\n",
        "\n",
        "# Nous r√©utilisons les Callbacks simplifi√©s\n",
        "mini_unet_callbacks_simple = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, verbose=1, restore_best_weights=True),\n",
        "]\n",
        "\n",
        "history_mini_new = model_mini_unet.fit(\n",
        "    train_gen_color,\n",
        "    validation_data=val_gen_color,\n",
        "    epochs=30,\n",
        "    callbacks=mini_unet_callbacks_simple,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- 3. Affichage des Courbes ---\n",
        "plot_history(history_mini_new, title=\"Mini U-Net Performance (Nouveau Run)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4164a666",
      "metadata": {
        "id": "4164a666"
      },
      "outputs": [],
      "source": [
        "# --- Lancer la d√©mo sur le Baseline Model ---\n",
        "# On utilise test_df pour √™tre honn√™te (images jamais vues)\n",
        "predict_and_plot(model_mini_unet, test_df, n_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AyUKdAmunSRw",
      "metadata": {
        "id": "AyUKdAmunSRw"
      },
      "source": [
        "## Entra√Ænement Simple U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OQXjKyLTGZV9",
      "metadata": {
        "id": "OQXjKyLTGZV9"
      },
      "outputs": [],
      "source": [
        "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = inputs\n",
        "\n",
        "    # --- ENCODEUR (La Descente) ---\n",
        "    # On garde 4 niveaux pour la complexit√©, mais on contr√¥le les filtres.\n",
        "\n",
        "    # Niveau 1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    # Niveau 2\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    # Niveau 3\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # Niveau 4\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    # --- BOTTLENECK OPTIMIS√â ---\n",
        "    # Au lieu de 256, on met 160. C'est le secret pour rester autour de 1M.\n",
        "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    # --- D√âCODEUR (La Remont√©e) ---\n",
        "\n",
        "    # Remont√©e Niveau 4\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    # Remont√©e Niveau 3\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    # Remont√©e Niveau 2\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    # Remont√©e Niveau 1\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    # Sortie (Masque binaire)\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"‚úÖ Mod√®le Optimis√© (~1M params) d√©fini !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cQDZ4r0io2x0",
      "metadata": {
        "collapsed": true,
        "id": "cQDZ4r0io2x0"
      },
      "outputs": [],
      "source": [
        "simple_unet = simple_unet_model(IMG_SIZE, IMG_SIZE, 3)\n",
        "simple_unet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wsIkoFM1nPhD",
      "metadata": {
        "id": "wsIkoFM1nPhD"
      },
      "outputs": [],
      "source": [
        "# 1. Nettoyage de la m√©moire\n",
        "K.clear_session()\n",
        "\n",
        "# 2. Instanciation (3 Canaux pour la couleur !)\n",
        "IMG_CHANNELS = 3\n",
        "model_unet_final = simple_unet_model(IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
        "\n",
        "# 3. Compilation\n",
        "# On garde un Learning Rate standard (1e-3) car le mod√®le est robuste\n",
        "model_unet_final.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                         loss=dice_coef_loss,\n",
        "                         metrics=['accuracy', dice_coef])\n",
        "\n",
        "unet_callbacks = [\n",
        "    # 1. EarlyStopping (Arr√™t Pr√©coce)\n",
        "    # Patiente 10 pour laisser le temps au mod√®le de d√©passer les petits plateaux.\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "\n",
        "    # 2. ReduceLROnPlateau (Ralentissement de l'apprentissage)\n",
        "    # Si la perte stagne pendant 5 √©poques, on ralentit pour forcer l'ajustement fin.\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,           # Diviser le Learning Rate par 5\n",
        "        patience=5,\n",
        "        min_lr=1e-7,          # Vitesse minimale de s√©curit√©\n",
        "        verbose=1\n",
        "    ),\n",
        "\n",
        "    # 3. ModelCheckpoint (Sauvegarde du meilleur mod√®le)\n",
        "    # Sauvegarde uniquement si le Dice Score de validation s'am√©liore.\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'unet_final_best.keras',\n",
        "        monitor='val_dice_coef',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RUTFYGAZojOA",
      "metadata": {
        "collapsed": true,
        "id": "RUTFYGAZojOA"
      },
      "outputs": [],
      "source": [
        "# 5. Entra√Ænement\n",
        "print(\"üöÄ Lancement du U-Net Complet sur images Couleur Contrast√©es...\")\n",
        "print(\"Objectif : Dice Score > 0.80\")\n",
        "\n",
        "history_final = model_unet_final.fit(\n",
        "    train_gen_color,\n",
        "    validation_data=val_gen_color,\n",
        "    epochs=50, # On augmente car le mod√®le est plus gros\n",
        "    callbacks=unet_callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6. Affichage\n",
        "plot_history(history_final, title=\"U-Net Complet (Final)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xfcd_GgXp403",
      "metadata": {
        "collapsed": true,
        "id": "Xfcd_GgXp403"
      },
      "outputs": [],
      "source": [
        "predict_and_plot(model_unet_final, test_df, n_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce046e4d",
      "metadata": {
        "id": "ce046e4d"
      },
      "outputs": [],
      "source": [
        "# Calcul du score Dice sur l'ensemble de test\n",
        "# Le mod√®le a √©t√© compil√© avec 'dice_coef' comme m√©trique\n",
        "loss, accuracy, dice = model_unet_final.evaluate(test_gen_color, verbose=1)\n",
        "\n",
        "print(f\"\\nPerformance finale sur l'ensemble de test :\")\n",
        "print(f\"  Loss (Dice Loss) : {loss:.4f}\")\n",
        "print(f\"  Accuracy         : {accuracy:.4f}\")\n",
        "print(f\"  Dice Coefficient : {dice:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fmRfHkHlxAWq",
        "758b2dbc",
        "79cebc1e",
        "1uLzsWpShhlZ",
        "9lDSGABuiaoL"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "brain_segmentation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
